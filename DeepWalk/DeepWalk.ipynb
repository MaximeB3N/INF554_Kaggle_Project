{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory : /users/eleves-a/2019/nathan.peluso/INF554/INF554_Kaggle_Project/DeepWalk, Project directory : /users/eleves-a/2019/nathan.peluso/INF554/INF554_Kaggle_Project\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.linear_model as LinearModels\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import *\n",
    "from scipy import stats\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "NathanPath=\"d:\\Documents\\Info\\INF554\\INF554_Kaggle_Project\"\n",
    "NathanPath=\"/users/eleves-a/2019/nathan.peluso/INF554/INF554_Kaggle_Project\"\n",
    "\n",
    "project_path = str(Path(os.getcwd()).parent.absolute())\n",
    "print(\"Current directory : \" + os.getcwd() + \", Project directory : \" + project_path)\n",
    "\n",
    "os.chdir(project_path)\n",
    "os.chdir(NathanPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read training data\n",
    "df_train = pd.read_csv('data/train.csv', dtype={'author': np.int64, 'hindex': np.float32})\n",
    "n_train = df_train.shape[0]\n",
    "\n",
    "# Read test data\n",
    "df_test = pd.read_csv('data/test.csv', dtype={'author': np.int64})\n",
    "n_test = df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes : 217801\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_edgelist('data/coauthorship.edgelist', delimiter=' ', nodetype=int)\n",
    "n=G.number_of_nodes()\n",
    "print(\"Number of nodes : \" + str(n))\n",
    "\n",
    "abs_nodeID_Graph=dict(enumerate(G.nodes))\n",
    "nodeID_abs_Graph=dict([(b,a) for a,b in enumerate(G.nodes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_nodeID_Train=dict(df_train[\"author\"])\n",
    "abs_hindex_Train=dict(df_train[\"hindex\"])\n",
    "nodeID_abs_Train=dict([(b,a) for a,b in abs_nodeID_Train.items()])\n",
    "\n",
    "abs_nodeID_Test=dict(df_test[\"author\"])\n",
    "nodeID_abs_Test=dict([(b,a) for a,b in abs_nodeID_Test.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(G, node, walk_length):\n",
    "    # Simulates a random walk of length \"walk_length\" starting from node \"node\"\n",
    "    walk=[node]\n",
    "    for _ in range(walk_length):\n",
    "        node=np.random.choice(list(G.neighbors(node)))\n",
    "        walk.append(node)\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_walks(G, num_walks, walk_length):\n",
    "    # Runs \"num_walks\" random walks from each node\n",
    "    walks = []\n",
    "    for x in G.nodes():\n",
    "        for _ in range(num_walks):\n",
    "            walks.append(random_walk(G,x,walk_length))\n",
    "    np.random.shuffle(walks)\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepwalk(G, num_walks, walk_length, n_dim):\n",
    "    # Simulates walks and uses the Skipgram model to learn node representations\n",
    "    print(\"Generating walks\")\n",
    "    walks = generate_walks(G, num_walks, walk_length)\n",
    "    print(\"Training word2vec\")\n",
    "    model = Word2Vec(vector_size=n_dim, window=8, min_count=0, sg=1, workers=8, hs=1)\n",
    "    model.build_vocab(walks)\n",
    "    model.train(walks, total_examples=model.corpus_count, epochs=5)\n",
    "    return model\n",
    "\n",
    "n_dim = 128\n",
    "n_walks = 50\n",
    "walk_length = 10\n",
    "#model = deepwalk(G, n_walks, walk_length, n_dim) \n",
    "#model.save(\"DeepWalk/Models/model_\"+str(n_walks)+'_'+str(walk_length)+'_'+str(n_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=Word2Vec.load(\"DeepWalk/Models/model_\"+str(n_walks)+'_'+str(walk_length)+'_'+str(n_dim))\n",
    "model=Word2Vec.load(\"DeepWalk/Models/model_30_10_128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.wv), G.number_of_nodes())\n",
    "list(model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=G.number_of_nodes()\n",
    "DeepWalk_embeddings = np.empty(shape=(n, n_dim))\n",
    "\n",
    "print(\"Filling embeddings\")\n",
    "for node in nodeID_abs_Graph.keys():\n",
    "    DeepWalk_embeddings[nodeID_abs_Graph[node]]=model.wv.get_vector(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(X,Y):\n",
    "    if (len(X)!=len(Y)):\n",
    "        print(\"Sizes not identical\")\n",
    "        return -1\n",
    "    return (X-Y)@(X-Y) / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=abs_nodeID_Train.__len__()\n",
    "\n",
    "idx=np.random.permutation(n)\n",
    "#Careful, those indexes are related to the TRAIN set, not to the global graph indexing\n",
    "idx_train=idx[:int(0.8*n)]\n",
    "idx_val=idx[int(0.8*n):]\n",
    "\n",
    "nodes_train=[abs_nodeID_Train[i] for i in idx_train]\n",
    "nodes_val=[abs_nodeID_Train[i] for i in idx_val]\n",
    "\n",
    "X_train_x = [DeepWalk_embeddings[nodeID_abs_Graph[i]] for i in nodes_train]\n",
    "X_val_x = [DeepWalk_embeddings[nodeID_abs_Graph[i]] for i in nodes_val]\n",
    "\n",
    "hindex_train_x=[abs_hindex_Train[i] for i in idx_train]\n",
    "hindex_val_x=[abs_hindex_Train[i] for i in idx_val]\n",
    "\n",
    "lin_reg=LinearModels.LinearRegression()\n",
    "lin_reg.fit(X_train_x,hindex_train_x)\n",
    "_pred=lin_reg.predict(X_val_x)\n",
    "score=MSE(hindex_val_x,_pred)\n",
    "\n",
    "print(\"Accuracy using DeepWalk embeddings \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model in proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=np.zeros((G.number_of_nodes(), n_dim + 1), dtype=np.float64)\n",
    "for i in range(G.number_of_nodes()):\n",
    "    M[i][0]=abs_nodeID_Graph[i]\n",
    "    M[i][1:]=model.wv.get_vector(M[i][0])\n",
    "np.save(\"DeepWalk/Models/output_proper.npy\", M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glob = [DeepWalk_embeddings[nodeID_abs_Graph[node]] for node in nodeID_abs_Train.keys()]\n",
    "hindex_train_glob=[abs_hindex_Train[nodeID_abs_Train[node]] for node in nodeID_abs_Train.keys()]\n",
    "X_test=[DeepWalk_embeddings[nodeID_abs_Graph[node]] for node in nodeID_abs_Test.keys()]\n",
    "nodes_test=[node for node in nodeID_abs_Test.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg=LinearModels.LinearRegression()\n",
    "lin_reg.fit(X_train_glob,hindex_train_glob)\n",
    "_pred=lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=dict([(nodes_test[i], _pred[i]) for i in range(len(X_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"submissions/deepwalk_lin_submission.csv\", 'w') as f:\n",
    "    f.write(\"author,hindex\\n\")\n",
    "    for k,h in submission.items():\n",
    "        f.write(str(k)+\",\"+str(h)+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline = pd.read_csv('submissions/baseline_submission.csv', dtype={'author': np.float64})\n",
    "baseline_dict=dict(np.array(df_baseline))\n",
    "df_mine = pd.read_csv('submissions/deepwalk_lin_submission.csv', dtype={'author': np.float64})\n",
    "mine_dict=dict(np.array(df_mine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(baseline_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base=[baseline_dict.get(node) for node in baseline_dict.keys()]\n",
    "mine_reordered=[mine_dict.get(node) for node in baseline_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE(base,mine_reordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing improved regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Core number OK\n",
      "Degree OK\n",
      "Neighb degree OK\n",
      "Clustering OK\n",
      "Degree centrality OK\n"
     ]
    }
   ],
   "source": [
    "model=Word2Vec.load(\"DeepWalk/Models/model_30_10_128\")\n",
    "G = nx.read_edgelist('data/coauthorship.edgelist', delimiter=' ', nodetype=int)\n",
    "n=G.number_of_nodes()\n",
    "\n",
    "print(\"Starting\")\n",
    "core_n=nx.core_number(G)\n",
    "print(\"Core number OK\")\n",
    "degrees=nx.degree(G)\n",
    "print(\"Degree OK\")\n",
    "surr_mean_deg=nx.average_neighbor_degree(G)\n",
    "print(\"Neighb degree OK\")\n",
    "coef_clust=nx.clustering(G)\n",
    "print(\"Clustering OK\")\n",
    "deg_cent=nx.degree_centrality(G)\n",
    "print(\"Degree centrality OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim=model.wv.vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217801/217801 [00:01<00:00, 155375.61it/s]\n"
     ]
    }
   ],
   "source": [
    "DeepWalk_embeddings_i = np.empty(shape=(n, n_dim+7))\n",
    "print(\"Filling embeddings\")\n",
    "for node in tqdm(G.nodes):\n",
    "    DeepWalk_embeddings_i[nodeID_abs_Graph[node]][0]=node\n",
    "    DeepWalk_embeddings_i[nodeID_abs_Graph[node]][1]=core_n[node]\n",
    "    DeepWalk_embeddings_i[nodeID_abs_Graph[node]][2]=degrees[node]\n",
    "    DeepWalk_embeddings_i[nodeID_abs_Graph[node]][3]=degrees[node]*degrees[node]\n",
    "    DeepWalk_embeddings_i[nodeID_abs_Graph[node]][4]=surr_mean_deg[node]\n",
    "    DeepWalk_embeddings_i[nodeID_abs_Graph[node]][5]=coef_clust[node]\n",
    "    DeepWalk_embeddings_i[nodeID_abs_Graph[node]][6]=deg_cent[node]\n",
    "    DeepWalk_embeddings_i[nodeID_abs_Graph[node]][7:]=model.wv.get_vector(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"DeepWalk/embeddings_improved.npy\", DeepWalk_embeddings_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=abs_nodeID_Train.__len__()\n",
    "\n",
    "idx=np.random.permutation(n_train)\n",
    "#Careful, those indexes are related to the TRAIN set, not to the global graph indexing\n",
    "idx_train=idx[:int(0.8*n_train)]\n",
    "idx_val=idx[int(0.8*n_train):]\n",
    "\n",
    "nodes_train=[abs_nodeID_Train[i] for i in idx_train]\n",
    "nodes_val=[abs_nodeID_Train[i] for i in idx_val]\n",
    "core_n=nx.core_number(G)\n",
    "degrees=nx.degree(G)\n",
    "\n",
    "X_train_x = [DeepWalk_embeddings_i[nodeID_abs_Graph[i]] for i in nodes_train]\n",
    "X_val_x = [DeepWalk_embeddings_i[nodeID_abs_Graph[i]] for i in nodes_val]\n",
    "\n",
    "hindex_train_x=[abs_hindex_Train[i] for i in idx_train]\n",
    "hindex_val_x=[abs_hindex_Train[i] for i in idx_val]\n",
    "\n",
    "lin_reg=LinearModels.LinearRegression()\n",
    "lin_reg.fit(X_train_x,hindex_train_x)\n",
    "_pred=lin_reg.predict(X_val_x)\n",
    "score=MSE(hindex_val_x,_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy using DeepWalk embeddings++ \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Simple MLP model\"\"\"\n",
    "    def __init__(self, n_feat, n_hidden_1, n_hidden_2, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(n_feat, n_hidden_1)\n",
    "        self.fc2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.fc3 = nn.Linear(n_hidden_2, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z0 = self.relu(self.fc1(x))\n",
    "        z0 = self.dropout(z0)\n",
    "        z1 = self.relu(self.fc2(z0))\n",
    "        out = self.fc3(z1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=abs_nodeID_Train.__len__()\n",
    "#DeepWalk_embeddings_i=np.load(\"DeepWalk/embeddings_improved.npy\")\n",
    "DeepWalk_embeddings_i=np.load(\"Global/full_embedding_matrix.npy\")\n",
    "\n",
    "n_feat=DeepWalk_embeddings_i.shape[1]\n",
    "\n",
    "idx=np.random.permutation(n)\n",
    "#Careful, those indexes are related to the TRAIN set, not to the global graph indexing\n",
    "idx_train=idx[:int(0.8*n)]\n",
    "idx_val=idx[int(0.8*n):]\n",
    "\n",
    "nodes_train=[abs_nodeID_Train[i] for i in idx_train]\n",
    "nodes_val=[abs_nodeID_Train[i] for i in idx_val]\n",
    "\n",
    "X_train_x = torch.tensor([DeepWalk_embeddings_i[nodeID_abs_Graph[i]] for i in nodes_train], dtype=torch.float32)\n",
    "X_val_x = torch.tensor([DeepWalk_embeddings_i[nodeID_abs_Graph[i]] for i in nodes_val], dtype=torch.float32)\n",
    "\n",
    "hindex_train_x=torch.tensor([abs_hindex_Train[i] for i in idx_train], dtype=torch.float32)\n",
    "hindex_val_x=torch.tensor([abs_hindex_Train[i] for i in idx_val], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim=X_train_x.shape[1]\n",
    "model=MLP(n_dim,256,64,0.4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train_x)\n",
    "    loss_train = loss(output.reshape(-1), hindex_train_x)\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    output= model(X_val_x)\n",
    "\n",
    "    loss_val = loss(output.reshape(-1), hindex_val_x)\n",
    "    print('Epoch: {:03d}'.format(epoch+1),\n",
    "            'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "            'loss_val: {:.4f}'.format(loss_val.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"DW_MLP_Models/1000ep-2lr0.1dr_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepWalk_embeddings_i=np.load(\"DeepWalk/embeddings_improved.npy\")\n",
    "X_train_glob = torch.tensor([DeepWalk_embeddings_i[nodeID_abs_Graph[node]] for node in nodeID_abs_Train.keys()], dtype=torch.float32)\n",
    "hindex_train_glob=torch.tensor([abs_hindex_Train[nodeID_abs_Train[node]] for node in nodeID_abs_Train.keys()], dtype=torch.float32)\n",
    "X_test=torch.tensor([DeepWalk_embeddings_i[nodeID_abs_Graph[node]] for node in nodeID_abs_Test.keys()], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim=X_train_x.shape[1]\n",
    "model=MLP(n_dim,256,64,0.4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train_glob)\n",
    "    loss_train = loss(output.reshape(-1), hindex_train_glob)\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch: {:03d}'.format(epoch+1),\n",
    "            'loss_train: {:.4f}'.format(loss_train.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pred=model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=dict([(nodes_test[i], _pred[i]) for i in range(len(X_test))])\n",
    "with open(\"submissions/deepwalk_MLP_submission.csv\", 'w') as f:\n",
    "    f.write(\"author,hindex\\n\")\n",
    "    for k,h in submission.items():\n",
    "        f.write(str(k)+\",\"+str(h.item())+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "571ac4587ae4eeb6b02353bd76aeaaf0ceca15cf49d684242a7eb1fb5d42efb7"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('myEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

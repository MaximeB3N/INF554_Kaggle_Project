{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import *\n",
    "from scipy import stats\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "NathanPath=\"d:\\Documents\\Info\\INF554\\INF554_Kaggle_Project\"\n",
    "NathanPath=\"/users/eleves-a/2019/nathan.peluso/INF554/INF554_Kaggle_Project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = str(Path(os.getcwd()).parent.absolute())\n",
    "print(\"Current directory : \" + os.getcwd() + \", Project directory : \" + project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(project_path)\n",
    "os.chdir(NathanPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read training data\n",
    "df_train = pd.read_csv('data/train.csv', dtype={'author': np.int64, 'hindex': np.float32})\n",
    "n_train = df_train.shape[0]\n",
    "\n",
    "# Read test data\n",
    "df_test = pd.read_csv('data/test.csv', dtype={'author': np.int64})\n",
    "n_test = df_test.shape[0]\n",
    "\n",
    "df_dummy_sub = pd.read_csv('submissions/dummy_submission.csv', dtype={'author': np.int64, 'hindex': np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist('data/coauthorship.edgelist', delimiter=' ', nodetype=int)\n",
    "n=G.number_of_nodes()\n",
    "print(\"Number of nodes : \" + str(n))\n",
    "\n",
    "abs_nodeID_Graph=dict(enumerate(G.nodes))\n",
    "nodeID_abs_Graph=dict([(b,a) for a,b in enumerate(G.nodes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_nodeID_Train=dict(df_train[\"author\"])\n",
    "abs_hindex_Train=dict(df_train[\"hindex\"])\n",
    "nodeID_abs_Train=dict([(b,a) for a,b in abs_nodeID_Train.items()])\n",
    "\n",
    "abs_nodeID_Test=dict(df_test[\"author\"])\n",
    "abs_hindex_Test=dict(df_test[\"hindex\"])\n",
    "nodeID_abs_Test=dict([(b,a) for a,b in abs_nodeID_Test.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"train_dict=[(a,b) for a,b in np.array(df_train, dtype=np.int64)]\n",
    "id_train=[i for i,_ in train_dict]\n",
    "id_test=[x for x,_ in np.array(df_test, dtype=np.int64)]\n",
    "\n",
    "idx = np.random.permutation(len(id_train))\n",
    "\n",
    "idx_train_indexes=idx[:int(0.8*len(id_train))]\n",
    "idx_train = [id_train[i] for i in idx_train_indexes]\n",
    "idx_val_indexes=idx[int(0.8*len(id_train)):]\n",
    "idx_val = [id_train[i] for i in idx_val_indexes]\n",
    "\n",
    "\n",
    "\n",
    "G_train=G.subgraph(id_train)\n",
    "h_index_train=[x for _,x in train_dict]\n",
    "\n",
    "print(len(idx_train))\n",
    "print(len(idx_val))\n",
    "\n",
    "h_index_trainx=[h_index_train[x] for x in idx[:int(0.8*len(id_train))]]\n",
    "h_index_valx=[h_index_train[x] for x in idx[int(0.8*len(id_train)):]]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(G, node, walk_length):\n",
    "    # Simulates a random walk of length \"walk_length\" starting from node \"node\"\n",
    "    walk=[]\n",
    "    for _ in range(walk_length):\n",
    "        node=np.random.choice(list(G.neighbors(node)))\n",
    "        walk.append(node)\n",
    "    walk = [node for node in walk]\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_walks(G, num_walks, walk_length):\n",
    "    # Runs \"num_walks\" random walks from each node\n",
    "    walks = []\n",
    "    for x in G.nodes():\n",
    "        for _ in range(num_walks):\n",
    "            walks.append(random_walk(G,x,walk_length))\n",
    "    np.random.shuffle(walks)\n",
    "    return walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepwalk(G, num_walks, walk_length, n_dim):\n",
    "    # Simulates walks and uses the Skipgram model to learn node representations\n",
    "    print(\"Generating walks\")\n",
    "    walks = generate_walks(G, num_walks, walk_length)\n",
    "    print(\"Training word2vec\")\n",
    "    model = Word2Vec(vector_size=n_dim, window=8, min_count=0, sg=1, workers=8, hs=1)\n",
    "    model.build_vocab(walks)\n",
    "    model.train(walks, total_examples=model.corpus_count, epochs=5)\n",
    "    return model\n",
    "\n",
    "n_dim = 128\n",
    "n_walks = 10\n",
    "walk_length = 10\n",
    "#model = deepwalk(G, n_walks, walk_length, n_dim) \n",
    "#model.save(\"DeepWalk/Models/model_\"+str(n_walks)+'_'+str(walk_length)+'_'+str(n_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=Word2Vec.load(\"DeepWalk/Models/model_\"+str(n_walks)+'_'+str(walk_length)+'_'+str(n_dim))\n",
    "model=Word2Vec.load(\"DeepWalk/Models/model_10_10_128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.wv), G.number_of_nodes())\n",
    "list(model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepWalk_embeddings = np.empty(shape=(n, n_dim))\n",
    "\n",
    "print(\"Filling embeddings\")\n",
    "for i in range(G.number_of_nodes()):\n",
    "    try:\n",
    "        DeepWalk_embeddings[i]=model.wv[i]\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSE(X,Y):\n",
    "    return (X-Y)@(X-Y) / len(X)\n",
    "\n",
    "\"\"\"X_train_x = [DeepWalk_embeddings[i] for i in idx_train_indexes]\n",
    "X_validate_x = [DeepWalk_embeddings[i] for i in idx_val_indexes]\n",
    "\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train_x,h_index_trainx)\n",
    "_pred=lin_reg.predict(X_validate_x)\n",
    "score=RSE(h_index_valx,_pred)\n",
    "\n",
    "\n",
    "print(\"Accuracy using DeepWalk embeddings \", score)\"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "571ac4587ae4eeb6b02353bd76aeaaf0ceca15cf49d684242a7eb1fb5d42efb7"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('myEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
